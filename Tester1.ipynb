{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7Z+5IbxI+pbfOU3nQ89h7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamB2603/IAyRN/blob/Main/Tester1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto de la clase Inteligencia Artificial y Redes Neuronales.\n",
        "# Ramiro Emiliano Martinez De La Cruz - 2014197 - Martes M4\n",
        "# María Fernanda Garza Barbosa - 1945003 - Martes N4\n",
        "# Karla Judith Corona Castro - 1923390 - Martes N4\n",
        "# Abraham Giovanni Aguirre Bravo - 2014222 - Martes N4\n"
      ],
      "metadata": {
        "id": "aNA5ZQfykKxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción"
      ],
      "metadata": {
        "id": "0tCpaSvqqbd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este proyecto se hizo con la finalidad de brindar apoyo a las personas que presentan alguna discapacidad del habla, facilitando su interacción con quienes no comparten sus mismas formas de comunicación. La idea es desarrollar una herramienta que interprete el lenguaje de señas mexicano, permitiendo que los gestos realizados por los usuarios puedan ser reconocidos y traducidos ya sea en acciones concretas o en mensajes hablados o escritos que reflejen sus pensamientos y emociones.\n",
        "\n",
        "Este enfoque busca reducir la barrera comunicativa entre quienes utilizan lenguaje de señas y quienes no lo comprenden, promoviendo así una comunicación más fluida, inclusiva y accesible para ambas partes. Para lograrlo, se emplearán servomotores y una cámara de video, elementos clave que permitirán captar e interpretar los movimientos de las manos con precisión, haciendo posible la implementación de este sistema."
      ],
      "metadata": {
        "id": "CtUN7Zjnuxtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Librerias"
      ],
      "metadata": {
        "id": "8qn-I0gSs0qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar librerías\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import pickle\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qzwWac3zt1Re"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento"
      ],
      "metadata": {
        "id": "kmZodQLzvDAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de librerías necesarias\n",
        "import pickle\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. CARGAR ARCHIVO .PICKLE\n",
        "ruta_pickle = '/content/drive/My Drive/Datasets/NUMEROS.pickle'\n",
        "\n",
        "# Abrir y cargar el contenido del archivo .pickle\n",
        "with open(ruta_pickle, 'rb') as archivo:\n",
        "    data = pickle.load(archivo)\n",
        "\n",
        "# Mostrar información sobre el contenido cargado\n",
        "print(\"Tipo del objeto cargado desde el archivo pickle:\", type(data))\n",
        "if hasattr(data, \"shape\"):\n",
        "    print(\"Dimensiones del objeto:\", data.shape)\n",
        "    # Si el objeto es similar a una imagen (por ejemplo, un arreglo NumPy), se visualiza:\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(data, cmap='gray')\n",
        "    plt.title(\"Imagen cargada desde .pickle\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"El objeto cargado no posee atributo 'shape'; revise el contenido del pickle.\")\n",
        "\n",
        "\n",
        "# 2. CARGAR IMAGEN DE PRUEBA CON OpenCV\n",
        "file = '/content/numero.png'\n",
        "test_image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Verificar que la imagen se haya cargado correctamente\n",
        "if test_image is None:\n",
        "    print(\"No se encontró la imagen en la ruta especificada:\", file)\n",
        "else:\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(test_image, cmap='gray')\n",
        "    plt.title(\"Imagen de prueba cargada con cv2\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jpm6Fun-vLzw",
        "outputId": "926ede01-d29f-485a-faa8-25d9c9e6c4ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo del objeto cargado desde el archivo pickle: <class 'list'>\n",
            "El objeto cargado no posee atributo 'shape'; revise el contenido del pickle.\n",
            "No se encontró la imagen en la ruta especificada: /content/numero.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Formato de imagen\n",
        "img_resized = cv2.resize(test_image, (28,28), )\n",
        "img_resized = cv2.bitwise_not(img_resized)\n",
        "\n",
        "# Preview de imagen reformateada\n",
        "Numeros='/content/Numeros'\n",
        "plt.imshow(img_resized, cmap='gray')\n",
        "plt.savefig(\"/content/Numeros/abc.png\")\n",
        "# Numeros.download(\"abc.png\")\n",
        "\n",
        "# Dentro del ciclo for, vamos a generar las ETIQUETAS para cada imagen (enteros del 0 - 9).\n",
        "img_resized.append()"
      ],
      "metadata": {
        "id": "JYrNxqddvUWA",
        "outputId": "cd846d0d-d613-4101-8335-5d6740aa4601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-72b3fb380a7c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Formato de imagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Preview de imagen reformateada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el dataset en 80% para entrenamiento y 20% para validación, o 70% - 30%.\n",
        "# ¡Invesigar!\n",
        "\n",
        "train_images\n",
        "train_labels\n",
        "test_images\n",
        "test_labels"
      ],
      "metadata": {
        "id": "q9CcgBnLvclF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento: visualización de variables y normalización de imagenes.\n",
        "train_images.shape"
      ],
      "metadata": {
        "id": "Hy9h2Yw3zgEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "id": "yRPXV5CTv4Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "WLkVPW7iv57h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "id": "ai3nsrI0v_VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_labels)"
      ],
      "metadata": {
        "id": "saguJZEowBAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización de valores de pixeles.\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "J6W62xIXwJQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Estructura y entrenamiento de Red Neuronal Artificial Convolusional (RNAC)"
      ],
      "metadata": {
        "id": "EccXwS3O0lzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parte convolusional de la RNAC\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "BSG2JWvHMtLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parte de clasificación\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10), activation = 'softmax')"
      ],
      "metadata": {
        "id": "ihPuUm6nMuiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compliación del modelo: características\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SAfi-KejMym1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de la RNAC\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "Ox_mNbzvNPaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resultados de exactitud de la RNAC"
      ],
      "metadata": {
        "id": "w_WNMVfyNaz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfica con la diferencia de valores de exactitud del entrenamiento y la validación.\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.4, 1])\n",
        "plt.xlim([-1, 11])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "metadata": {
        "id": "Dwpn9XCpNd7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicciones con la RNAC entrenada"
      ],
      "metadata": {
        "id": "vSbtQZJZNl_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images_generadasporustedes)"
      ],
      "metadata": {
        "id": "nckqLJ4hNrSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = predictions[1]\n",
        "y = test_labels[1]\n",
        "print(\"La red dice que la imagen es clase \" + x + \"y la clase verdadera es: \" + y)"
      ],
      "metadata": {
        "id": "8yaJLMWQNvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = predictions[50]\n",
        "y = test_labels[50]\n",
        "print(\"La red dice que la imagen es clase \" + x + \"y la clase verdadera es: \" + y)"
      ],
      "metadata": {
        "id": "0dbVWucIN3Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = predictions[40]\n",
        "y = test_labels[40]\n",
        "print(\"La red dice que la imagen es clase \" + x + \"y la clase verdadera es: \" + y)"
      ],
      "metadata": {
        "id": "G0KMnR5yN6xn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}